{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbb6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f88e61",
   "metadata": {},
   "source": [
    "# Random Seeding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11793b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41d186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentance of Equal Lenth Problem \n",
    "# After eos nothing should contribute into Loss\n",
    "# How Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b61989a",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c913c8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>झुको!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>बतख़!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English  Hindi\n",
       "0    Wow!   वाह!\n",
       "1   Duck!  झुको!\n",
       "2   Duck!  बतख़!\n",
       "3   Help!  बचाओ!\n",
       "4   Jump.  उछलो."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the text \n",
    "df = pd.read_csv('hin.txt',sep='\\t')\n",
    "df = df.drop(\"2\",axis=1)\n",
    "\n",
    "df.columns = [\"English\",\"Hindi\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bff83a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    wow!\n",
       "1                                                   duck!\n",
       "2                                                   duck!\n",
       "3                                                   help!\n",
       "4                                                   jump.\n",
       "                              ...                        \n",
       "2910    if you go to that supermarket, you can buy mos...\n",
       "2911    the passengers who were injured in the acciden...\n",
       "2912    democracy is the worst form of government, exc...\n",
       "2913    if my boy had not been killed in the traffic a...\n",
       "2914    when i was a kid, touching bugs didn't bother ...\n",
       "Name: English, Length: 2915, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"English\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924f21d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_casing(df):\n",
    "    for i in df.columns:\n",
    "        df[i] = df[i].str.lower()\n",
    "    return df\n",
    "\n",
    "def apply_start_end_tokens(df):\n",
    "    for i in df.columns:\n",
    "        df[i] = df[i].apply(lambda x: \"<sos> \" + x + \" <eos>\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4ef98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;sos&gt; wow! &lt;eos&gt;</td>\n",
       "      <td>&lt;sos&gt; वाह! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;sos&gt; duck! &lt;eos&gt;</td>\n",
       "      <td>&lt;sos&gt; झुको! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;sos&gt; duck! &lt;eos&gt;</td>\n",
       "      <td>&lt;sos&gt; बतख़! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;sos&gt; help! &lt;eos&gt;</td>\n",
       "      <td>&lt;sos&gt; बचाओ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;sos&gt; jump. &lt;eos&gt;</td>\n",
       "      <td>&lt;sos&gt; उछलो. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             English              Hindi\n",
       "0   <sos> wow! <eos>   <sos> वाह! <eos>\n",
       "1  <sos> duck! <eos>  <sos> झुको! <eos>\n",
       "2  <sos> duck! <eos>  <sos> बतख़! <eos>\n",
       "3  <sos> help! <eos>  <sos> बचाओ! <eos>\n",
       "4  <sos> jump. <eos>  <sos> उछलो. <eos>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = lower_casing(df)\n",
    "df = apply_start_end_tokens(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adea29fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'when',\n",
       " 'i',\n",
       " 'was',\n",
       " 'a',\n",
       " 'kid,',\n",
       " 'touching',\n",
       " 'bugs',\n",
       " \"didn't\",\n",
       " 'bother',\n",
       " 'me',\n",
       " 'a',\n",
       " 'bit.',\n",
       " 'now',\n",
       " 'i',\n",
       " 'can',\n",
       " 'hardly',\n",
       " 'stand',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'pictures',\n",
       " 'of',\n",
       " 'them.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df['English'].str.cat(sep=' ')\n",
    "train_df.split(\" \")[-24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36aadd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<sos> when i was a kid, touching bugs didn't bother me a bit. now i can hardly stand looking at pictures of them. <eos>\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"English\"].values[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668bdd43",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "348fd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language:\n",
    "    def __init__(self,data=List[list],lang=str):\n",
    "        self._data = data\n",
    "        self._lang = lang\n",
    "        self.words = self._load_words()\n",
    "        \n",
    "        self.uniq_words = self._get_unique_words()\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "        \n",
    "    def _load_words(self):\n",
    "        text = self._data[self._lang].str.cat(sep=\" \")\n",
    "        return text.split(\" \")\n",
    "    \n",
    "    def _get_unique_words(self):\n",
    "        words = Counter(self.words)\n",
    "        return sorted(words, key=words.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed03b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "english = Language(df,\"English\")\n",
    "hindi = Language(df,\"Hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a10ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pairs(Dataset):\n",
    "    def __init__(self,data):\n",
    "        self._data = data\n",
    "        self.hindi = Language(df,\"Hindi\")\n",
    "        self.english = Language(df,\"English\")\n",
    "        \n",
    "    def get_data(self):\n",
    "        holder = []\n",
    "        for i in self._data.values:\n",
    "            input_ = [self.english.word_to_index[word] for word in i[0].split(' ')]\n",
    "            output_ = [self.hindi.word_to_index[word] for word in i[1].split(' ')]\n",
    "            \n",
    "            holder.append((torch.tensor(input_,dtype=torch.long).view(-1,1),\n",
    "                          torch.tensor(output_,dtype=torch.long).view(-1,1)))\n",
    "        return holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cda8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = Pairs(df)\n",
    "pairs = pair.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0dc93a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[   0],\n",
       "          [1548],\n",
       "          [   1]]),\n",
       "  tensor([[   0],\n",
       "          [1506],\n",
       "          [   1]])),\n",
       " (tensor([[  0],\n",
       "          [954],\n",
       "          [  1]]),\n",
       "  tensor([[   0],\n",
       "          [1507],\n",
       "          [   1]]))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b1a62",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b107356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0208394",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41c398d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size,hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_, hidden):\n",
    "        output = self.embedding(input_).view(1,1, -1)\n",
    "        output = F.relu(output,inplace=False)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        prediction = self.out(output[0].clone())\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5459cb62",
   "metadata": {},
   "source": [
    "# Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae5d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Seq2Seq(nn.Module):\n",
    "#     def __init__(self, encoder, decoder):\n",
    "#         super().__init__()\n",
    "#         self.encoder = encoder\n",
    "#         self.decoder = decoder\n",
    "#         self.encoder_hidden = encoder.initHidden()\n",
    "     \n",
    "#     def forward(self, source, target):\n",
    "#         #get the input length (number of words in sentence)\n",
    "#         input_length = source.size(0)\n",
    "#         target_length = target.shape[0]\n",
    "        \n",
    "#         batch_size = target.shape[1] \n",
    "#         vocab_size = self.decoder.vocab\n",
    "        \n",
    "#         outputs = torch.zeros(target_length, batch_size, vocab_size)\n",
    "        \n",
    "#         for i in range(input_length):\n",
    "#             encoder_output, encoder_hidden = self.encoder(source[i],self.encoder_hidden)\n",
    "            \n",
    "#         decoder_input = target[0].clone()\n",
    "        \n",
    "#         for t in range(target_length):\n",
    "#             decoder_output, decoder_hidden = self.decoder(decoder_input, encoder_hidden)\n",
    "#             outputs[t] = decoder_output.detach()\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "#         return outputs        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777cda3",
   "metadata": {},
   "source": [
    "# Custom Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4614f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(0,2)\n",
    "input_size = len(english.index_to_word)\n",
    "output_size = len(hindi.index_to_word)\n",
    "hidden_size = 128\n",
    "batch_size = 1 \n",
    "\n",
    "#create encoder-decoder model\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "#print(\"Encoder : \\n\",encoder)\n",
    "decoder = Decoder(output_size, hidden_size)\n",
    "#print(\"Decoder : \\n\",decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88795e0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch ': 0, 'Sentence ': 2914, 'Loss ': 6.351917743682861}\n",
      "{'Epoch ': 1, 'Sentence ': 2914, 'Loss ': 6.005764484405518}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "en_optimizer = optim.Adam(encoder.parameters(),lr=0.001)\n",
    "de_optimizer = optim.Adam(decoder.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in epochs:\n",
    "    for sen, (source, target) in enumerate(pairs):\n",
    "        loss = 0\n",
    "        # set gradient zero\n",
    "        en_optimizer.zero_grad()\n",
    "        de_optimizer.zero_grad()\n",
    "        \n",
    "        input_length = source.size(0)\n",
    "        target_length = target.shape[0]\n",
    "        \n",
    "        batch_size = target.shape[1] \n",
    "        vocab_size = decoder.vocab\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size)\n",
    "\n",
    "        # encoder \n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(source[i],encoder_hidden)\n",
    "\n",
    "        # decoder\n",
    "        decoder_input = target[0].clone()\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for t in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            outputs[t] = decoder_output\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        # loss\n",
    "        loss +=criterion(outputs.transpose(2,1),target)\n",
    "    \n",
    "        # Backpropagation\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        de_optimizer.step()\n",
    "        en_optimizer.step()\n",
    "\n",
    "    print({\"Epoch \": epoch, \"Sentence \": sen, \"Loss \": loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa118e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen, (source, target) in enumerate(pairs):\n",
    "    if sen > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d25f0c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0],\n",
       "        [954],\n",
       "        [  1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35144c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0],\n",
       "        [1507],\n",
       "        [   1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
