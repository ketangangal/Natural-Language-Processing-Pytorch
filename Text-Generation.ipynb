{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806422a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e42a748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  138k  100  138k    0     0   256k      0 --:--:-- --:--:-- --:--:--  256k\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/amoudgl/short-jokes-dataset/master/data/reddit-cleanjokes.csv > data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7f88f",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc2529e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What did the bartender say to the jumper cable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Don't you hate jokes about German sausage? The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Two artists had an art contest... It ended in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Why did the chicken cross the playground? To g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What gun do you use to hunt a moose? A moosecut!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Joke\n",
       "0   1  What did the bartender say to the jumper cable...\n",
       "1   2  Don't you hate jokes about German sausage? The...\n",
       "2   3  Two artists had an art contest... It ended in ...\n",
       "3   4  Why did the chicken cross the playground? To g...\n",
       "4   5   What gun do you use to hunt a moose? A moosecut!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv(\"data.txt\")\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8fd6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'did',\n",
       " 'the',\n",
       " 'bartender',\n",
       " 'say',\n",
       " 'to',\n",
       " 'the',\n",
       " 'jumper',\n",
       " 'cables?',\n",
       " 'You']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(temp[\"Joke\"].str.cat(sep=\" \").split(' ')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b2aac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>you</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>a</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "5     to   458\n",
       "15   you   486\n",
       "0   What   530\n",
       "32     a   964\n",
       "2    the  1057"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(temp[\"Joke\"].str.cat(sep=\" \").split(' '))\n",
    "pd.DataFrame(counts.items()).sort_values(1).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a935d44",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d054a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,sequence_length):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        # Word Tokenization\n",
    "        train_df = pd.read_csv('data.txt')\n",
    "        text = train_df['Joke'].str.cat(sep=' ')\n",
    "        return text.split(' ')\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        # sequence length might me input time stemps\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ddb6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"max-epochs\":100,\"batch-size\":256,\"sequence-length\":4}\n",
    "dataset = Dataset(args[\"sequence-length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1549d43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23914"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10abf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 0, 248, 20, 4, 0, 1905, 1906, 64]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.words_indexes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d96f2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23910"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1369258",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0844bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  2,   8,   0, 248],\n",
      "        [  8,   0, 248,  20],\n",
      "        [  0, 248,  20,   4],\n",
      "        [248,  20,   4,   0]]), tensor([[   8,    0,  248,   20],\n",
      "        [   0,  248,   20,    4],\n",
      "        [ 248,   20,    4,    0],\n",
      "        [  20,    4,    0, 1905]])]\n",
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    print(data)\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42300864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 128\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=n_vocab, embedding_dim=self.embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_size,\n",
    "                            hidden_size=self.lstm_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            dropout=0.2)\n",
    "        \n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n",
    "    \n",
    "    \n",
    "model = Model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2859cf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embedding): Embedding(6925, 128)\n",
      "  (lstm): LSTM(128, 128, num_layers=3, dropout=0.2)\n",
      "  (fc): Linear(in_features=128, out_features=6925, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d7f78a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred will be having (batch,vocab,seq)\n",
    "# y will be having (batch,seq)\n",
    "\n",
    "# Then take max column wise in seq then calculate loss\n",
    "def train(dataset, model, args):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=args[\"batch-size\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(args[\"max-epochs\"]):\n",
    "        state_h, state_c = model.init_state(args[\"sequence-length\"])\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c88c232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(dataset, model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f450ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, next_words=100):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        #words.append(dataset.index_to_word[p.argmax()])\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "a7e8e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knock knock. Whos there? i am your box of driving Greg? When got true in jokes I said lost by anywhere. joke it watched it kicked my ceremony The dog morning she'll going to waste. this with my pasta? \"Don't years... conversation... last lacked He's -- says they dish have you, video I'm sheep Why once one of two kin! fell morning... Why are caterpillars move? knock machine one has this car -I down you're one in scratch. What did the storm say to the neutron You like me through my Ten chew, Their old. Why did the dry decide when he had It May my pet.\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(predict(dataset, model, text='Knock knock. Whos there? i am your')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "aa109d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 176,  510,  993,  177, 1462,  294,    3]])\n",
      "tensor([[ 510,  993,  177, 1462,  294,    3]])\n",
      "tensor([[ 993,  177, 1462,  294,    3]])\n",
      "tensor([[ 177, 1462,  294,    3]])\n",
      "tensor([[1462,  294,    3]])\n",
      "tensor([[294,   3]])\n",
      "tensor([[3]])\n",
      "tensor([], size=(1, 0))\n",
      "tensor([], size=(1, 0))\n",
      "tensor([], size=(1, 0))\n"
     ]
    }
   ],
   "source": [
    "words = 'Knock knock. Whos there? i am you'.split(' ')\n",
    "for i in range(0,10):\n",
    "    torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "    print(torch.tensor([[dataset.word_to_index[w] for w in words[i:]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5f32dbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 10])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = nn.Linear(5,10)(y)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "887f2077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((256, 6925, 4))\n",
    "b = torch.ones((256, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "817063f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.8429)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "a = torch.ones((256, 6925, 4),dtype=torch.float)\n",
    "b = torch.ones((256, 4), dtype=torch.long)\n",
    "criteria(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5ea8e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.randint(0,10,(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c5f2113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9, 0],\n",
       "        [7, 4, 4, 9],\n",
       "        [2, 8, 8, 0],\n",
       "        [0, 3, 6, 5],\n",
       "        [9, 9, 5, 2]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "65be07d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([9, 9, 9, 9]),\n",
       "indices=tensor([4, 4, 0, 1]))"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "25868626",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "fa8e8cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 6925, 4])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "fef1e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.1181, 0.1179, 0.1152, 0.1182], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([3463, 1378, 3463, 3463]))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0].max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "75f423b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  8,   0, 248,  20])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
